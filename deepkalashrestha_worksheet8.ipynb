{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Step 1"
      ],
      "metadata": {
        "id": "kVhn3q7eW8--"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building a custom decision tree with information gain"
      ],
      "metadata": {
        "id": "pWOikoMbYHNt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cIIIkJXOWd2c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class CustomDecisionTree:\n",
        "  def __init__(self, max_depth=None):\n",
        "    self.max_depth = max_depth\n",
        "    self.tree = None\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    self.tree = self._build_tree(X, y)\n",
        "\n",
        "  def _build_tree(self, X, y, depth=0):\n",
        "    num_samples, num_features = X.shape\n",
        "    unique_classes = np.unique(y)\n",
        "\n",
        "    if len(unique_classes) == 1:\n",
        "      return {'class': unique_classes[0]}\n",
        "\n",
        "    if num_samples == 0 or (self.max_depth and depth >= self.max_depth):\n",
        "      return {'class': np.bincount(y).argmax()}\n",
        "\n",
        "    best_info_gain = -float('inf')\n",
        "    best_split = None\n",
        "\n",
        "    for feature_idx in range(num_features):\n",
        "      thresholds = np.unique(X[:, feature_idx])\n",
        "\n",
        "      for threshold in thresholds:\n",
        "        left_mask = X[:, feature_idx] <= threshold\n",
        "        right_mask = ~left_mask\n",
        "        left_y = y[left_mask]\n",
        "        right_y = y[right_mask]\n",
        "\n",
        "        info_gain = self._information_gain(y, left_y, right_y)\n",
        "\n",
        "        if info_gain > best_info_gain:\n",
        "          best_info_gain = info_gain\n",
        "          best_split = {\n",
        "            'feature_idx': feature_idx,\n",
        "            'threshold': threshold,\n",
        "            'left_y': left_y,\n",
        "            'right_y': right_y,\n",
        "          }\n",
        "\n",
        "      if best_split is None:\n",
        "        return {'class': np.bincount(y).argmax()}\n",
        "\n",
        "    left_tree = self._build_tree(\n",
        "      X[best_split['left_y']],\n",
        "      best_split['left_y'],\n",
        "      depth + 1\n",
        "    )\n",
        "\n",
        "    right_tree = self._build_tree(\n",
        "      X[best_split['right_y']],\n",
        "      best_split['right_y'],\n",
        "      depth + 1\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'feature_idx': best_split['feature_idx'],\n",
        "      'threshold': best_split['threshold'],\n",
        "      'left_tree': left_tree,\n",
        "      'right_tree': right_tree\n",
        "    }\n",
        "\n",
        "  def _information_gain(self, parent, left, right):\n",
        "    parent_entropy = self._entropy(parent)\n",
        "    left_entropy = self._entropy(left)\n",
        "    right_entropy = self._entropy(right)\n",
        "\n",
        "    weighted_avg_entropy = (\n",
        "      (len(left) / len(parent)) * left_entropy +\n",
        "      (len(right) / len(parent)) * right_entropy\n",
        "    )\n",
        "\n",
        "    return parent_entropy - weighted_avg_entropy\n",
        "\n",
        "  def _entropy(self, y):\n",
        "    class_probs = np.bincount(y) / len(y)\n",
        "    return -np.sum(class_probs * np.log2(class_probs + 1e-9))\n",
        "\n",
        "  def predict(self, X):\n",
        "    return [self._predict_single(x, self.tree) for x in X]\n",
        "\n",
        "  def _predict_single(self, x, tree):\n",
        "    if 'class' in tree:\n",
        "      return tree['class']\n",
        "    feature_val = x[tree['feature_idx']]\n",
        "    if feature_val<=tree['threshold']:\n",
        "      return self._predict_single(x, tree['left_tree'])\n",
        "    else:\n",
        "      return self._predict_single(x, tree['right_tree'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2"
      ],
      "metadata": {
        "id": "1z3x1GTLXA3X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load and split iris dataset"
      ],
      "metadata": {
        "id": "S1dL91qAYL73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "ky6F42FqXCUP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3"
      ],
      "metadata": {
        "id": "k2-ki-5OXEYo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train and Evaluate a custom decision tree"
      ],
      "metadata": {
        "id": "FMDx0XMuYRAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "custom_tree = CustomDecisionTree(max_depth=3)\n",
        "custom_tree.fit(X_train, y_train)\n",
        "y_pred_custom = custom_tree.predict(X_test)\n",
        "accuracy_custom = accuracy_score(y_test, y_pred_custom)"
      ],
      "metadata": {
        "id": "Um7njuhVXE0v"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4"
      ],
      "metadata": {
        "id": "g_45GYZ3XJEj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train and Evaluate a Scikit learn decision tree"
      ],
      "metadata": {
        "id": "7PFdBuUwYUny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sklearn_tree = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "sklearn_tree.fit(X_train, y_train)\n",
        "y_pred_sklearn = sklearn_tree.predict(X_test)\n",
        "accuracy_sklearn = accuracy_score(y_test, y_pred_sklearn)\n",
        "print(f\"Scikit-learn Decision Tree Accuracy: {accuracy_sklearn:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MQvwQmfXKNu",
        "outputId": "13ab793c-9c8d-48b8-9b1c-e00bf2d75ad2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scikit-learn Decision Tree Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Result comparision"
      ],
      "metadata": {
        "id": "1fS-fcAOXMLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Accuracy comparision\")\n",
        "print(f\"Custom Decision Tree Accuracy: {accuracy_custom:.4f}\")\n",
        "print(f\"Scikit-learn Decision Tree Accuracy: {accuracy_sklearn:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8DGsRLDXNVN",
        "outputId": "7d30ebb9-4af3-49ef-9dc0-b504e3931594"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy comparision\n",
            "Custom Decision Tree Accuracy: 0.8000\n",
            "Scikit-learn Decision Tree Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 3. Exercise:"
      ],
      "metadata": {
        "id": "IMG23TYSXO3o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensemble Methods and Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "sXXO_0UzYjKJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the wine dataset"
      ],
      "metadata": {
        "id": "ePEc0UbbXRBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "data = load_wine()\n",
        "X = data.data\n",
        "y = data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "0mQNIv0AXSDw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1"
      ],
      "metadata": {
        "id": "Lg2-OjQhXUA9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement Classification Models"
      ],
      "metadata": {
        "id": "e6cNuhDgYay1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "custom_forest = RandomForestClassifier(max_depth=3)\n",
        "custom_forest.fit(X_train, y_train)\n",
        "y_pred_custom = custom_forest.predict(X_test)\n",
        "f1_custom = f1_score(y_test, y_pred_custom, average='weighted')\n",
        "custom_tree2 = DecisionTreeClassifier(max_depth=3)\n",
        "custom_tree2.fit(X_train, y_train)\n",
        "y_pred_custom2 = custom_tree2.predict(X_test)\n",
        "f1_custom2 = f1_score(y_test, y_pred_custom2, average='weighted')\n",
        "print(f\"Custom Random Forest F1 Score: {f1_custom:.4f}\")\n",
        "print(f\"Custom Decision Tree F1 Score: {f1_custom2:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRcwSmc6XU6Z",
        "outputId": "d501ffea-6517-461f-e222-ebe2cf52373d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom Random Forest F1 Score: 1.0000\n",
            "Custom Decision Tree F1 Score: 0.9449\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameter tuning"
      ],
      "metadata": {
        "id": "EYdm3Bm3XWbq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "param_grid = {\n",
        "   'n_estimators': [100, 200],\n",
        "   'max_depth': [None, 10, 20],\n",
        "   'min_samples_split': [2, 5],\n",
        "   'min_samples_leaf': [1, 2],\n",
        "   'bootstrap': [True, False]\n",
        "}\n",
        "grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "print(\"Best Params:\", grid_search.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpdwggMFXX2G",
        "outputId": "7bfd4a30-c838-4d9c-9627-68020e8b28b6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Params: {'bootstrap': True, 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing regression model"
      ],
      "metadata": {
        "id": "HdK3lL9IXZcy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "regressor = DecisionTreeRegressor(random_state=0)\n",
        "regressor.fit(X, y)\n",
        "y_pred_dr = regressor.predict(X_test)\n",
        "random_forest_regressor = RandomForestRegressor(n_estimators=100, random_state=0)\n",
        "random_forest_regressor.fit(X, y)\n",
        "y_pred_rfr = random_forest_regressor.predict(X_test)\n",
        "#hyperparameter tuning\n",
        "param_grid2= {\n",
        "'n_estimators': [100, 200],\n",
        "'max_depth': [None, 10, 20],\n",
        "'min_samples_split': [2, 5],\n",
        "'min_samples_leaf': [1, 2],\n",
        "'bootstrap': [True, False]\n",
        "}\n",
        "random_search = RandomizedSearchCV(RandomForestClassifier(), param_grid, cv=5)\n",
        "random_search.fit(X_train, y_train)\n",
        "print(\"Best Params:\", random_search.best_params_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NJg5AVqXaj0",
        "outputId": "bc04e69a-5e52-4a60-ea7c-a9c89056093a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Params: {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 10, 'bootstrap': True}\n"
          ]
        }
      ]
    }
  ]
}